---
title: "seurat train"
author: "Han Songqiao"
date: "2022/2/8"
output: pdf_document
---

```{r}
library(dplyr)
library(Seurat)
library(patchwork)
#Load the PBMC dataset
pbmc.data<-Read10X(data.dir="D:/1leiden/Internship&Thesis/Seurat_data_set/filtered_gene_bc_matrices/hg19/")
```


```{r}
#Initialize the Seurat object with the raw (non-normalized data)
pbmc<-CreateSeuratObject(counts=pbmc.data,project="pbmc3k",min.cells=3,min.features=200)
pbmc
```
#What does data in a count matrix look like?

```{r}
#Let's examine a few genes in the first thirty cells
pbmc.data[c("CD3D","TCL1A","MS4A1"),1:30]
```

The . values in the matrix represent 0s (no molecules detected). Since most values in an scRNA-seq matrix are 0, Seurat uses a sparse-matrix representation whenever possible. This results in significant memory and speed savings for Drop-seq/inDrop/10X data.

```{r}
dense.size = object.size(as.matrix(pbmc.data))
dense.size
```
```{r}
sparse.size=object.size(pbmc.data)
sparse.size
```
```{r}
dense.size/sparse.size
```

Standard pre-processing workflow

The steps below encompass the standard workflow for scRNA-seq data in Seurat. These represent the selection and filtration of cells based on QC metrics, data normalization and scaling, and the detection of highly variable features.

QC and selecting cells for further analysis

Seurat allows you to easily explore QC metrics and filter cells based on any user-defined criteria. A few QC metrics commonly used by the community include
1. The number of unique genes detected in each cell.
(1) Low-quality cells or empty droplets will often have very few genes.
(2) Cell doublets or multiplets may exhibit an aberrantly high gene coun.
2. Similarly, the total number of molecules detected within a cell(correlates strongly with unique genes)
3. The percentage of reads that map to the mitochondrial contamination
(1) Low-quality/drying cells often exhibit extensive mitochondrial contamination.
(2) We calculate mitochondrial QC metrics with the PercentageFeatureSet() function, which calculates the percentage of counts originating from a set of features.
(3) We use the set of all genes starting with MT- as a set of mitochondrial genes.
```{r}
#The [[ operator can add to columns to object metadata. This is a great place to stash QC stats
pbmc[["percent.mt"]]<-PercentageFeatureSet(pbmc,pattern="^MT-") #short for
```

Where are QC metrics stored in Seurat?

The number of unique genes and total molecules are automatically calculated during CreateSeuratObject().
~ You can find them stored in the object meta data.

```{r}
#Show QC metrics for the first 5 cells
head(pbmc@meta.data,5)
```
In this example below, we visualize QC metrics, and use these to filter cells.

(1) We filter cells that have unique feature counts over 2500 or less than 200
(2) We filter cells that have >5% mitochondrial counts.

violin plot select the cells which have unique feature counts over 2500 or less than 200.
Select cells >5% mitochondrial counts.
```{r}
VlnPlot(pbmc,features = c("nFeature_RNA","nCount_RNA","percent.mt"),ncol=3)
```

```{r}
#FeatureScatter is typically used to visualize feature-feature relationships, but can
#used for anything calculated by the object, i.e. columns in object metadata, PC score, etc.
plot1<-FeatureScatter(pbmc,feature1="nCount_RNA",feature2="percent.mt")
plot2<-FeatureScatter(pbmc,feature1="nCount_RNA",feature2="nFeature_RNA")
plot1+plot2
```

```{r}
pbmc<-subset(pbmc,subset=nFeature_RNA >200 & nFeature_RNA <2500 & percent.mt < 5 )
```

Normalizing the data

After removing unwanted cells from the dataset, the next step is to normalize the data. By default, we employ a global-scaling normaliaztion method "LogNomalize" that normalize the feature expression measurements for each cell by the total expression, multiplies this by a scale factor(10000 by default), and log-transforms the result. Normalized values are stored in pbmc[["RNA"]]@data.
```{r}
pbmc<-NormalizeData(pbmc,normalization.method = "LogNormalize",scale.factor = 10000)
```

For clarity, in this previous line of code (and in future commands), we provide the default values for certain parameters in the function call. However, this isn't required and the same behavior can be achieved with:
```{r}
pbmc <- NormalizeData(pbmc)
```

Identification of highly variable features
Feature Selection
We next calculate a subset of features that exhibit high cell-to-cell variation in the dataset(i.e. they are highly expressed in some cells, and lowly expressed in others.)
Improves on previous versions by directly modeling the mean-vaiance relationship inherent in single-cell data, and is implemented in the FindVariableFeatures() Function. By default, we return 2000 features per dataset. These will be used in downstream analysis, like PCA.
```{r}
pbmc <- FindVariableFeatures(pbmc, selection.method = "vst", nfeatures = 2000)

# Identify the 10 most highly variable genes
top10 <- head(VariableFeatures(pbmc), 10)

# plot variable features with and without labels
plot1 <- VariableFeaturePlot(pbmc)
plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE)
plot1
plot2
```

Scaling the data
Next, we apply a linear transformation ('scaling') that is a standard pre-processing prior to dimensional reduction techniques like PCA. The ScaleData() function:
(1) Shifts the expression of each gene, so that the mean expression across cells is 0.
(2) Scales the expression of each gene, so that the variance across cells is 1.
This step gives equal weight in downstream analyses, so that highly-expressed genes do not dominate.
(3) The results of this are stored in pbmc[["RNA"]]@sclae.data

```{r}
all.genes <- rownames(pbmc)
pbmc<-ScaleData(pbmc,features = all.genes)
```

Perform linear dimension reduction
Next we perform PCA on the scaled data. By default, only the previous determined variable features are used as input, but can be defined using features argument if you wish to choose a different subset.

PCA analysis

```{r}
pbmc<- RunPCA(pbmc,features = VariableFeatures(object=pbmc))
print(pbmc[["pca"]],dims=1:5,nfeatures = 5)
```

```{r}
VizDimLoadings(pbmc,dims=1:2,reduction = "pca")
```

```{r}
DimPlot(pbmc,reduction = "pca")
```

In particular DimHeatmap() allows for easy exploration of the primary sources of heterogeneity in a dataset, and can be useful when trying to decide which PCs to include for further downstream analyses. Both cells and features are ordered according to their PCA scores. Setting cells to a number plots the 'extreme' cells on both ends of the specturm, which dramatically speeds plotting for large datasets. Though clearly a supervised analysis, we find this to be a valuable tool for exploring correlated feature sets.
```{r}
DimHeatmap(pbmc,dims=1,cells=500,balanced = TRUE)
DimHeatmap(pbmc, dims = 1:15, cells = 500, balanced = TRUE)
```

Determine the Dimensionality
```{r}
pbmc <- JackStraw(pbmc, num.replicate = 100)
pbmc <- ScoreJackStraw(pbmc, dims = 1:20)
```

```{r}
JackStrawPlot(pbmc, dims = 1:15)
ElbowPlot(pbmc)
```
10

Clustering the cells
```{r}
pbmc <- FindNeighbors(pbmc, dims = 1:10)
pbmc <- FindClusters(pbmc, resolution = 0.5)
```


```{r}
table(pbmc@active.ident)
```
```{r}
subpbmc<-subset(x = pbmc,idents="0")
subpbmc
```

```{r}
data1=subset(as.data.frame(pbmc@active.ident),pbmc@active.ident=="0")
```
```{r}
data2=as.data.frame(pbmc.data)
```

```{r}
name=rownames(data1)
data3=as.data.frame(name)
data4=as.data.frame(matrix(nrow=32738,ncol=711))
```


```{r}
data5=as.data.frame(matrix(nrow=32738,ncol=711))
```

```{r}
for (i in 1:711){
  data5[,i]=data2[,colnames(data2)==data3[i,]]
}
```


```{r}
colnames(data4)=data3$name
```
```{r}
row.names(data4)=row.names(data2)
```

```{r}
data4=data4[which(rowSums(data4)> 0),]
```

```{r}
write.csv(x = data4,file = "rawdata.csv")
```
